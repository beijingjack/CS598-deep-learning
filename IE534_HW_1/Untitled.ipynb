{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "#load MNIST data\n",
    "MNIST_data = h5py.File('MNISTdata.hdf5', 'r')\n",
    "x_train = np.float32(MNIST_data['x_train'][:] )\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0]))\n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()\n",
    "#Implementation of stochastic gradient descent algorithm\n",
    "#number of inputs\n",
    "num_inputs = 28*28\n",
    "#number of outputs\n",
    "num_outputs = 10\n",
    "model = {}\n",
    "#number of units in hidden layer\n",
    "dH = 30\n",
    "#Initialization parameters\n",
    "model['W'] = np.random.randn(dH,num_inputs) / np.sqrt(num_inputs)\n",
    "model['b1']= np.random.randn(dH) / np.sqrt(num_inputs)\n",
    "model['b2'] = np.random.randn(num_outputs) / np.sqrt(num_inputs)\n",
    "model['C'] = np.random.randn(num_outputs,dH) / np.sqrt(num_inputs)\n",
    "model_grads = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_function(z):\n",
    "    ZZ = np.exp(z)/np.sum(np.exp(z))\n",
    "    return ZZ\n",
    "\n",
    "def ReLu(Z):\n",
    "    return np.maximum(Z,0)\n",
    "\n",
    "def ReLuPrime(Z):\n",
    "    Z[Z>=0] = 1\n",
    "    Z[Z<0] = 0\n",
    "    return Z.astype(int)\n",
    "\n",
    "def forward(x,y, model):\n",
    "    Z = np.dot(model['W'], x) + model['b1']\n",
    "    H = ReLu(Z)\n",
    "    U = np.dot(model['C'],H) + model['b2']\n",
    "    p = softmax_function(U)\n",
    "    return p,H,Z\n",
    "\n",
    "def backward(x,y,p,H,Z,model, model_grads):\n",
    "    dU = -1.0*p\n",
    "    dU[y] = dU[y] + 1.0\n",
    "    # b2 gradient\n",
    "    model_grads['b2'] = dU\n",
    "    # C gradient\n",
    "    model_grads['C'] = np.outer(dU,H)\n",
    "    # delta\n",
    "    delta = np.dot(model['C'].T,dU)\n",
    "    # b1 gradient\n",
    "    model_grads['b1'] = delta * ReLuPrime(Z)\n",
    "    # W1 gradient\n",
    "    model_grads['W'] = np.outer(model_grads['b1'], x)\n",
    "    return model_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140333333333334\n",
      "0.9552666666666667\n",
      "0.9630833333333333\n",
      "0.9696166666666667\n",
      "0.9713333333333334\n",
      "0.9736833333333333\n",
      "0.9822333333333333\n",
      "0.9840833333333333\n",
      "0.9855666666666667\n",
      "0.98595\n",
      "0.98755\n",
      "0.9872\n",
      "0.9878333333333333\n",
      "0.9876166666666667\n",
      "0.9876333333333334\n",
      "0.9876166666666667\n",
      "0.9874666666666667\n",
      "0.98805\n",
      "0.9885666666666667\n",
      "0.9878666666666667\n",
      "217.10775589942932\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time1 = time.time()\n",
    "LR = .01\n",
    "num_epochs = 20\n",
    "for epochs in range(num_epochs):\n",
    "    #Learning rate schedule\n",
    "    if (epochs > 5):\n",
    "        LR = 0.001\n",
    "    if (epochs > 10):\n",
    "        LR = 0.0001\n",
    "    if (epochs > 15):\n",
    "        LR = 0.00001\n",
    "    total_correct = 0\n",
    "    for n in range( len(x_train)):\n",
    "        n_random = randint(0,len(x_train)-1 )\n",
    "        y = y_train[n_random]\n",
    "        x = x_train[n_random][:]\n",
    "        p,H,Z = forward(x, y, model)\n",
    "        prediction = np.argmax(p)\n",
    "        if (prediction == y):\n",
    "            total_correct += 1\n",
    "        model_grads = backward(x,y,p,H,Z,model, model_grads)\n",
    "        model['C'] = model['C'] + LR*model_grads['C']\n",
    "        model['b2'] = model['b2'] + LR*model_grads['b2']\n",
    "        model['b1'] = model['b1'] + LR*model_grads['b1']\n",
    "        model['W'] = model['W'] + LR*model_grads['W'] # changed from + to -\n",
    "    print(total_correct/np.float(len(x_train) ) )\n",
    "        \n",
    "time2 = time.time()\n",
    "print(time2-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9703\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "#test data\n",
    "total_correct = 0\n",
    "for n in range( len(x_test)):\n",
    "    y = y_test[n]\n",
    "    x = x_test[n][:]\n",
    "    p = forward(x, y, model)[0]\n",
    "    prediction = np.argmax(p)\n",
    "    if (prediction == y):\n",
    "        total_correct += 1\n",
    "print(total_correct/np.float(len(x_test) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
